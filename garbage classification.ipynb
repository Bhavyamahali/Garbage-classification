{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099004c-6aa3-4c28-9dc9-08620e7eba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Importing NumPy for numerical operations and array manipulations\n",
    "import matplotlib.pyplot as plt  # Importing Matplotlib for plotting graphs and visualizations\n",
    "import seaborn as sns  # Importing Seaborn for statistical data visualization, built on top of Matplotlib\n",
    "import tensorflow as tf  # Importing TensorFlow for building and training machine learning models\n",
    "from tensorflow import keras  # Importing Keras, a high-level API for TensorFlow, to simplify model building\n",
    "from tensorflow.keras import Layer  # Importing Layer class for creating custom layers in Keras\n",
    "from tensorflow.keras.models import Sequential  # Importing Sequential model for building neural networks layer-by-layer\n",
    "from tensorflow.keras.layers import Rescaling , GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers, optimizers, callbacks  # Importing various modules for layers, optimizers, and callbacks in Keras\n",
    "from sklearn.utils.class_weight import compute_class_weight  # Importing function to compute class weights for imbalanced datasets\n",
    "from tensorflow.keras.applications import EfficientNetV2B2  # Importing EfficientNetV2S model for transfer learning\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # Importing functions to evaluate model performance\n",
    "import gradio as gr  # Importing Gradio for creating interactive web interfaces for machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f10388-5da7-473b-bcf8-156a54a6d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir= r\"C:\\Users\\Edunet Foundation\\Downloads\\project\\garbage\\TrashType_Image_Dataset\"\n",
    "image_size = (124, 124)\n",
    "batch_size = 32\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef821d-0e91-4881-80fd-4625a8fed3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    shuffle = True,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a997626a-ffd4-46e5-92f4-27a20ae6fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    shuffle = True,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "val_class= val_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473e49b-9822-42dd-a781-a192e41556b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of batches in the validation dataset\n",
    "val_batches = tf.data.experimental.cardinality(val_ds)  \n",
    "\n",
    "# Split the validation dataset into two equal parts:\n",
    "# First half becomes the test dataset\n",
    "test_ds = val_ds.take(val_batches // 2)  \n",
    "\n",
    "# Second half remains as the validation dataset\n",
    "val_dat = val_ds.skip(val_batches // 2)  \n",
    "\n",
    "# Optimize test dataset by caching and prefetching to improve performance\n",
    "test_ds_eval = test_ds.cache().prefetch(tf.data.AUTOTUNE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87880fc-7314-498d-af96-da95254be800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(train_ds.class_names)\n",
    "print(val_class)\n",
    "print(len(train_ds.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c860fac-ece0-494f-874b-bccccca79fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(12):\n",
    "    ax = plt.subplot(4, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(train_ds.class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e28e63-2995-4205-b058-00a55d922c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_distribution(dataset, class_names):\n",
    "    total = 0\n",
    "    counts = {name: 0 for name in class_names}\n",
    "    \n",
    "    for _, labels in dataset:\n",
    "        for label in labels.numpy():\n",
    "            class_name = class_names[label]\n",
    "            counts[class_name] += 1\n",
    "            total += 1\n",
    "\n",
    "    for k in counts:\n",
    "        counts[k] = round((counts[k] / total) * 100, 2)  # Convert to percentage\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a2bb0-7008-46d5-9041-ad0d757c2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot class distribution\n",
    "def simple_bar_plot(dist, title):\n",
    "    plt.bar(dist.keys(), dist.values(), color='cornflowerblue')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58004d34-af5d-41f3-abe6-14df1e10b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "\n",
    "# Get class distributions\n",
    "train_dist = count_distribution(train_ds, class_names)\n",
    "val_dist = count_distribution(val_ds, class_names)\n",
    "test_dist = count_distribution(test_ds, class_names)\n",
    "overall_dist = {}\n",
    "for k in class_names:\n",
    "    overall_dist[k] = round((train_dist[k] + val_dist[k]) / 2, 2)\n",
    "\n",
    "print(train_dist)\n",
    "print(val_dist)\n",
    "print(test_dist)\n",
    "print(overall_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabbf975-f31f-45e3-876e-30d70f6194ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show visualizations\n",
    "simple_bar_plot(train_dist, \"Training Set Class Distribution (%)\")\n",
    "simple_bar_plot(val_dist, \"Validation Set Class Distribution (%)\")\n",
    "simple_bar_plot(test_dist, \"Test Set Class Distribution (%)\")\n",
    "simple_bar_plot(overall_dist, \"Overall Class Distribution (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa98e92-758d-4a26-8996-921a7e9c0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count class occurrences and prepare label list\n",
    "class_counts = {i: 0 for i in range(len(class_names))}\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    for label in labels.numpy():\n",
    "        class_counts[label] += 1\n",
    "        all_labels.append(label)\n",
    "\n",
    "# Compute class weights (index aligned)\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(class_names)),\n",
    "    y=all_labels\n",
    ")\n",
    "\n",
    "# Create dictionary mapping class index to weight\n",
    "class_weights = {i: w for i, w in enumerate(class_weights_array)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be9d9b-1ce3-48c2-9954-0af537656378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Optional: print results\n",
    "print(\"Class Counts:\", class_counts)\n",
    "print(\"Class Weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffad62a-d35f-4921-aed1-d189cee82746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define data augmentation pipeline\n",
    "data_augmentation = Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00381e6-8815-4b97-b9da-ac93f1b7da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load the pretrained MobileNetV3Small model (without the top classification layer)\n",
    "base_model = EfficientNetV2B2(include_top=False, input_shape=(124, 124, 3),include_preprocessing=True, weights='imagenet')\n",
    "\n",
    "\n",
    "#  Freeze early layers (to retain general pretrained features)\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:  # You can adjust this number\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b31ff1-7c13-4cdb-acf1-61fbe236b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Build the final model\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(124, 124, 3)),\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(6, activation='softmax')  # Change to your number of classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec1dfc-c812-4755-ac5f-e6f9c530b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029f027-3874-42cf-a217-5589e892305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an EarlyStopping callback to stop training when validation loss stops improving\n",
    "early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',            # Metric to monitor (validation loss here)\n",
    "    patience=3,                   # Number of epochs to wait after last improvement before stopping\n",
    "    restore_best_weights=True     # After stopping, restore the model weights from the epoch with the best val_loss\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ebfbf1-bffb-4978-b87f-9b3dae45828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs to train the model\n",
    "epochs = 15  # Number of times the model will go through the entire dataset\n",
    "\n",
    "# Train the model using the fit function\n",
    "history = model.fit(\n",
    "    train_ds,                # Training dataset used to adjust model weights\n",
    "    validation_data=val_ds,   # Validation dataset to monitor performance on unseen data\n",
    "    epochs=epochs,           # Number of training cycles, referencing the variable set earlier\n",
    "    class_weight=class_weights,  # Handles class imbalances by assigning appropriate weights\n",
    "    batch_size=32,           # Number of samples processed in each training step\n",
    "    callbacks=[early]        # Implements early stopping to prevent unnecessary training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a818e-d970-4047-a5bd-4abfd2bdb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 Summary (optional but useful)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d6d9a-fa8d-4a81-a3ee-7245d8e04e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary() # Print the architecture summary of the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888699e-6398-4bc6-9f85-a918e1456ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ining Loss')         # Plot training loss\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')   # Plot validation loss\n",
    "plt.legend(loc='upper right')              # Place legend in upper-right corner\n",
    "plt.title('Training vs Validation Loss')   # Add acc = history.history['accuracy']          # Extract training accuracy from history\n",
    "val_acc = history.history['val_accuracy']  # Extract validation accuracy from history\n",
    "loss = history.history['loss']             # Extract training loss from history\n",
    "val_loss = history.history['val_loss']     # Extract validation loss from history\n",
    "\n",
    "epochs_range = range(len(acc))             # Define range for epochs based on accuracy length\n",
    "\n",
    "plt.figure(figsize=(10,8))                 # Set overall figure size for visualization\n",
    "\n",
    "plt.subplot(1,2,1)                         # Create first subplot (1 row, 2 columns, position 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')       # Plot training accuracy\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy') # Plot validation accuracy\n",
    "plt.legend(loc='lower right')              # Place legend in lower-right corner\n",
    "plt.title('Training vs Validation Accuracy') # Add title for accuracy plot\n",
    "\n",
    "plt.subplot(1,2,2)                         # Create second subplot (1 row, 2 columns, position 2)\n",
    "plt.plot(epochs_range, loss, label='Tratitle for loss plot\n",
    "\n",
    "plt.show()                                 # Display the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979ed9d-c0aa-4740-9ca2-f00261a66765",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds_eval)\n",
    "print(f'Test accuracy is{accuracy:.4f}, Test loss is {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f0da6-2818-4e8a-bb8a-2a168298e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true labels from all batches in the test dataset\n",
    "y_true = np.concatenate([y.numpy() for x, y in test_ds_eval], axis=0)  # Convert Tensor labels to NumPy array and concatenate them\n",
    "\n",
    "# Get predictions as probabilities from the model\n",
    "y_pred_probs = model.predict(test_ds_eval)  # Predict class probabilities for each sample in the test dataset\n",
    "\n",
    "# Convert probabilities to predicted class indices\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Select the class with the highest probability for each sample\n",
    "\n",
    "# Compute the confusion matrix to evaluate classification performance\n",
    "cm = confusion_matrix(y_true, y_pred)  # Generate confusion matrix comparing true labels to predicted labels\n",
    "\n",
    "# Print metrics to assess model performance\n",
    "print(cm)  # Display confusion matrix\n",
    "print(classification_report(y_true, y_pred))  # Print precision, recall, and F1-score for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89995b8b-72a6-4f1c-aaf4-26252b2a2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))  # Set figure size for better visualization\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d',  # Create heatmap using confusion matrix\n",
    "            xticklabels=class_names,  # Set class names for x-axis (predicted labels)\n",
    "            yticklabels=class_names,  # Set class names for y-axis (true labels)\n",
    "            cmap='Blues')  # Use a blue colormap for better contrast\n",
    "\n",
    "plt.xlabel('Predicted')  # Label x-axis as Predicted classes\n",
    "plt.ylabel('True')  # Label y-axis as True classes\n",
    "plt.title('Confusion Matrix')  # Add title to the heatmap\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3153a2b8-dd29-4199-881e-7c3c7cac87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract class names from the training dataset\n",
    "class_names = train_ds.class_names  \n",
    "\n",
    "# Take one batch of images and labels from the test dataset for evaluation\n",
    "for images, labels in test_ds_eval.take(1):  \n",
    "\n",
    "    # Generate predictions for the batch of images\n",
    "    predictions = model.predict(images)  \n",
    "\n",
    "    # Get the predicted class index for each image\n",
    "    pred_labels = tf.argmax(predictions, axis=1)  \n",
    "\n",
    "    # Loop through the first 8 images in the batch\n",
    "    for i in range(8):  \n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # Convert and display image\n",
    "        plt.title(f\"True: {class_names[labels[i]]}, Pred: {class_names[pred_labels[i]]}\")  # Show actual and predicted class\n",
    "        plt.axis(\"off\")  # Hide axes for better visualization\n",
    "        plt.show()  # Display the image with title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7646c1b-1762-40be-84a9-5c1a6b299585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in Keras format with architecture, weights, and training configuration\n",
    "model.save('Effiicientnetv2b2.keras')\n",
    "\n",
    "# Load your Keras model\n",
    "model = tf.keras.models.load_model('Effiicientnetv2b2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa87df3-acf8-4a8a-b047-8de213553286",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a6aa0-1483-4ba7-bc38-fc42560697e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40605be-02e7-4d4e-84bc-ed36ca0f08db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img):  \n",
    "    # Resize image to 124x124 pixels (Note: Comment says 128x128, but code resizes to 124x124)\n",
    "    img = img.resize((124, 124))  \n",
    "    \n",
    "    # Convert image to a NumPy array with float32 dtype\n",
    "    img_array = np.array(img, dtype=np.float32)  \n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    # Expand dimensions to match model input shape (adds a batch dimension)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  \n",
    "    \n",
    "    # Make a prediction using the trained model\n",
    "    prediction = model.predict(img_array)  \n",
    "    \n",
    "    # Get the index of the highest predicted probability\n",
    "    predicted_class_index = np.argmax(prediction)  \n",
    "    \n",
    "    # Map the predicted index to its corresponding class name\n",
    "    predicted_class_name = class_names[predicted_class_index]  \n",
    "    \n",
    "    # Extract confidence score (probability of the predicted class)\n",
    "    confidence = prediction[0][predicted_class_index]  \n",
    "    \n",
    "    # Return formatted prediction result with confidence score\n",
    "    return f\"Predicted: {predicted_class_name} (Confidence: {confidence:.2f})\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b88a7-b923-4cbe-b0fa-1d671174cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = gr.Interface(  \n",
    "    fn=classify_image,  # Function to classify image using the trained model  \n",
    "    inputs=gr.Image(type=\"pil\"),  # Accepts input as a PIL image  \n",
    "    outputs=\"text\"  # Outputs prediction as text  \n",
    ")  \n",
    "\n",
    "# Launch the interface  \n",
    "iface.launch()  # Start the Gradio interface for user interaction  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
